# **Spider_crawler(简介)**
![A38by4.jpg](https://s2.ax1x.com/2019/03/21/A38by4.jpg)
 
----
> ### 一些简单的爬虫案例,有助于对爬虫的入门和了解
----
# **编译环境**
 System | win10 1803 
---|---
 Python Version | [python3.6.2](https://www.python.org/downloads/release/python-362/) |
 Python IDE | [VS Code](https://code.visualstudio.com/)  / [Pycharm](https://www.jetbrains.com/pycharm/download/)
 Code size | ![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/hfg123/Spider_crawler.svg?style=flat-square)

----
# [Picture_spider(图片抓取)](https://github.com/SunRelease/Spider_crawler/tree/master/Picture_spider)

## **安装所需库**

### ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/lxml.svg?label=requests)
```
pip install requests
pip install urllib

```
----

###  [chick here to read README-Picture](https://github.com/SunRelease/Spider_crawler/blob/master/Picture_spider/README-Picture.md)

      
>* 1.这是一个支持壁纸抓取的软件,运行后将在本文件路径创建文件夹以及图片

>* 2.更多详情请了解README-Picture


***

----

# [Html_parse(网页抓取)](https://github.com/hfg123/Spider_crawler/tree/master/Html_parse)

## **安装所需库**

### ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/lxml.svg?label=lxml)  ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/beautifulsoup4.svg?label=beautifulsoup4)  ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pyquery.svg?label=pyquery)
```

pip install lxml
pip install beautifulsoup4
pip install pyquery

```
----

### [chick here to read README-Html_parse](https://github.com/hfg123/Spider_crawler/blob/master/Html_parse/README-Html_parse.md)

>* 1 这是运用基本原生的框架进行初步网页提取,**方法包括但不仅限于下面的方法**

>>*  beautifulsoup4,pyquery,正则表达式,xpath

>* 2 **主要是对简单的网页进行抓取,仅限于对反爬措施不强的网站**(update 4-2)

----
# [Douban_crawler(豆瓣)](https://github.com/hfg123/Spider_crawler/tree/master/Douban)

## **安装所需库**
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pandas.svg?label=pandas) ![PyPI](https://img.shields.io/pypi/v/Faker.svg?label=Faker)
```
pip install pandas
pip install Faker
```
----
### [chick here to read README-DOUBAN](https://github.com/hfg123/Spider_crawler/blob/master/Douban/README_Douban.md)

>* 1.这是一个关于豆瓣抓取的简单爬虫

>* 2.默认以csv文件生成在文件夹中,顺序为ID, title ,rate ,url

>* 3.如果想修改抓取抓取页数,**请参照84行文档修改案例**


----

# [Translate(翻译)](https://github.com/SunRelease/Spider_crawler/tree/master/Translate)

## **安装所需库**
![PyPI](https://img.shields.io/pypi/v/js2py.svg?label=js2py)

```
pip install js2py
```
----

### [chick here to read README](https://github.com/SunRelease/Spider_crawler/blob/master/Translate/README-Translate.md)

>* 1.关于爬取翻译API以及获取翻译结果

>* 2.可以支持目前大多数语种的翻译

>* 3.更多功能详见 README

----









